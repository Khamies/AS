{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Representation Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waleed-Daud/AS/blob/master/Representation_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePN5RKlup4EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import eager\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ_542cfq1Gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone  https://github.com/Waleed-Daud/AS.git\n",
        "% cd AS "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl0xCXPNN_Bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MMD special imports\n",
        "\n",
        "from functools import partial\n",
        "import utils\n",
        "slim = tf.contrib.slim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KraeQIjqLJH",
        "colab_type": "text"
      },
      "source": [
        "## Q1. Let’s start by just looking at the marginal distribution of each feature in each group (A = 0, A = 1). For each feature, fit a Gaussian to that feature for each group – this should give us two Gaussians (parameters μ 0 , σ 0 or μ 1 , σ 1 ) for each feature. Then, we’ll use these simple distributions to preprocess the features of group A = 0 and 1 so they more closely match each other. For each feature x for a point in group A = a, let the pre-processed a feature x 0 = x−μ σ a . This pre-processing step should match the first two moments of the features of each group. As in the previous question, learn a classifier g to predict Y and a classifier h to predict A from this pre-processed dataset. Report the accuracy and ∆ DP for g and accuracy and reweighted accuracy for h. What happened?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAO4CQm2qzka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl3Nujjq2np3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_dataframe(dataset,key,label):\n",
        "  \n",
        "  female_data_binary = dataset[key] == 1\n",
        "  male_data_binary = dataset[key] == 0\n",
        "  \n",
        "  male_data = dataset[male_data_binary]\n",
        "  female_data = dataset[female_data_binary]\n",
        "  \n",
        "  sex_male_label = male_data[label]\n",
        "  sex_female_label = female_data[label]\n",
        "  \n",
        "  sex_male_data  = male_data.drop(['y','A'], axis =1)\n",
        "  sex_female_data  = female_data.drop(['y','A'], axis =1)\n",
        "  \n",
        "  \n",
        "  return sex_male_data,sex_male_label, sex_female_data,sex_female_label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def filter_dataframe_dp(dataset,key,label):\n",
        "  \n",
        "  if key =='sex_Female':\n",
        "    female_data_binary = dataset[key] == 1\n",
        "    male_data_binary = dataset[key] == 0\n",
        "  \n",
        "    male_data = dataset[male_data_binary]\n",
        "    female_data = dataset[female_data_binary]\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    female_data_binary = dataset['A'] == 1\n",
        "    male_data_binary = dataset['A'] == 0\n",
        "  \n",
        "    male_data = dataset[male_data_binary]\n",
        "    female_data = dataset[female_data_binary]\n",
        "  \n",
        "  \n",
        "  sex_male_label = male_data[label]\n",
        "  sex_female_label = female_data[label]\n",
        "  \n",
        "  \n",
        "  A_male = male_data['A']\n",
        "  A_female = female_data['A']\n",
        "  \n",
        "  \n",
        "  sex_male_data  = male_data.drop(['y','A'], axis =1)\n",
        "  sex_female_data  = female_data.drop(['y','A'], axis =1)\n",
        "  \n",
        "  \n",
        "  return sex_male_data,sex_male_label,A_male  , sex_female_data,sex_female_label,A_female\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def convert_to_tensors(mlist):\n",
        "  tlist = []\n",
        "  for tensor in mlist:\n",
        "    tlist.append(tf.convert_to_tensor(tensor,dtype=tf.float32))\n",
        "  return tlist\n",
        "\n",
        "\n",
        "class Custom_Loss:\n",
        "  \n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "\n",
        "  def maximum_mean_discrepancy(self,x, y, kernel=utils.gaussian_kernel_matrix):\n",
        "    r\"\"\"Computes the Maximum Mean Discrepancy (MMD) of two samples: x and y.\n",
        "    Maximum Mean Discrepancy (MMD) is a distance-measure between the samples of\n",
        "    the distributions of x and y. Here we use the kernel two sample estimate\n",
        "    using the empirical mean of the two distributions.\n",
        "    MMD^2(P, Q) = || \\E{\\phi(x)} - \\E{\\phi(y)} ||^2\n",
        "                = \\E{ K(x, x) } + \\E{ K(y, y) } - 2 \\E{ K(x, y) },\n",
        "    where K = <\\phi(x), \\phi(y)>,\n",
        "      is the desired kernel function, in this case a radial basis kernel.\n",
        "    Args:\n",
        "        x: a tensor of shape [num_samples, num_features]\n",
        "        y: a tensor of shape [num_samples, num_features]\n",
        "        kernel: a function which computes the kernel in MMD. Defaults to the\n",
        "                GaussianKernelMatrix.\n",
        "    Returns:\n",
        "        a scalar denoting the squared maximum mean discrepancy loss.\n",
        "    \"\"\"\n",
        "    with tf.name_scope('MaximumMeanDiscrepancy'):\n",
        "      # \\E{ K(x, x) } + \\E{ K(y, y) } - 2 \\E{ K(x, y) }\n",
        "      cost = 0\n",
        "      for i in range(x.shape[0]):\n",
        "        \n",
        "        cost += tf.reduce_mean(kernel(x[i:i+64], x[i:i+64]))         # Batch Size = 64\n",
        "      \n",
        "      for i in range(y.shape[0]):\n",
        "        cost += tf.reduce_mean(kernel(y[i:i+64], y[i:i+64]))         # Batch Size = 64\n",
        "      \n",
        "      for i in range(x.shape[0]):\n",
        "        cost -= 2 * tf.reduce_mean(kernel(x[i:i+64], y[i:i+64]))      # Batch Size = 64\n",
        "\n",
        "      # We do not allow the loss to become negative.\n",
        "      cost = tf.where(cost > 0, cost, 0, name='value')\n",
        "      return cost\n",
        "\n",
        "    \n",
        "    \n",
        "  def mmd_loss(self, source_samples, target_samples, weight, scope=None):\n",
        "    \"\"\"Adds a similarity loss term, the MMD between two representations.\n",
        "    This Maximum Mean Discrepancy (MMD) loss is calculated with a number of\n",
        "    different Gaussian kernels.\n",
        "    Args:\n",
        "      source_samples: a tensor of shape [num_samples, num_features].\n",
        "      target_samples: a tensor of shape [num_samples, num_features].\n",
        "      weight: the weight of the MMD loss.\n",
        "      scope: optional name scope for summary tags.\n",
        "    Returns:\n",
        "      a scalar tensor representing the MMD loss value.\n",
        "    \"\"\"\n",
        "    sigmas = [\n",
        "        1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20, 25, 30, 35, 100,\n",
        "        1e3, 1e4, 1e5, 1e6\n",
        "    ]\n",
        "    gaussian_kernel = partial(\n",
        "        utils.gaussian_kernel_matrix, sigmas=tf.constant(sigmas))\n",
        "\n",
        "    loss_value = self.maximum_mean_discrepancy(\n",
        "        source_samples, target_samples, kernel=gaussian_kernel)\n",
        "    loss_value = tf.maximum(1e-4, loss_value) * weight\n",
        "    assert_op = tf.Assert(tf.is_finite(loss_value), [loss_value])\n",
        "    with tf.control_dependencies([assert_op]):\n",
        "      tag = 'MMD Loss'\n",
        "      if scope:\n",
        "        tag = scope + tag\n",
        "      tf.summary.scalar(tag, loss_value)\n",
        "      tf.losses.add_loss(loss_value)\n",
        "\n",
        "    return loss_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk0RmGNDq7pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading Data\n",
        "\n",
        "train_data = np.load(\"./adult/adult_train.npz\")\n",
        "\n",
        "test_data = np.load(\"./adult/adult_test.npz\")\n",
        "\n",
        "\n",
        "X_train = train_data.f.x\n",
        "y_train = train_data.f.y\n",
        "A_train = train_data.f.a\n",
        "\n",
        "X_test = test_data.f.x\n",
        "y_test = test_data.f.y\n",
        "A_test = test_data.f.a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4JxccDlrbaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns_file = open('./adult/adult_headers.txt','r')\n",
        "columns = columns_file.read()\n",
        "columns_names = columns.split(\"\\n\")\n",
        "\n",
        "X_train_frame = pd.DataFrame(X_train,columns=columns_names) \n",
        "y_train_frame = pd.DataFrame(y_train,columns=['y'])\n",
        "A_train_frame = pd.DataFrame(A_train,columns=['A'])\n",
        "\n",
        "X_test_frame = pd.DataFrame(X_test,columns=columns_names) \n",
        "y_test_frame = pd.DataFrame(y_test,columns=['y']) \n",
        "A_test_frame = pd.DataFrame(A_test,columns=['A'])\n",
        "\n",
        "dataset_train_frame = pd.concat([X_train_frame,y_train_frame,A_train_frame],axis=1)\n",
        "dataset_train_frame.fillna(0,inplace = True)\n",
        "\n",
        "dataset_test_frame =  pd.concat([X_test_frame,y_test_frame,A_test_frame],axis=1)\n",
        "dataset_test_frame.fillna(0,inplace = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz6GqsAT0jyz",
        "colab_type": "text"
      },
      "source": [
        "### 1- Normalize the Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5DUyDPps6jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_a0, y_train_a0, X_train_a1, y_train_a1 = filter_dataframe(dataset_train_frame,'A','y') \n",
        "X_test_a0, y_test_a0, X_test_a1, y_test_a1  = filter_dataframe(dataset_test_frame,'A','y')\n",
        "\n",
        "\n",
        "X_train_a0_norm = ( X_train_a0 - X_train_a0.mean() ) / X_train_a0.std()\n",
        "X_train_a1_norm = ( X_train_a1 - X_train_a1.mean() ) / X_train_a1.std()\n",
        "\n",
        "X_test_a0_norm = ( X_test_a0 - X_train_a0.mean() ) / X_train_a0.std()\n",
        "X_test_a1_norm = ( X_test_a1 - X_train_a1.mean() ) / X_train_a1.std()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train_frame = pd.concat([X_train_a0_norm,X_train_a1_norm], axis=0)\n",
        "X_test_frame =  pd.concat([X_test_a0_norm,X_test_a1_norm], axis=0)\n",
        "\n",
        "y_train_frame = pd.concat([y_train_a0,y_train_a1], axis=0)\n",
        "y_test_frame =  pd.concat([y_test_a0,y_test_a1], axis=0)\n",
        "\n",
        "\n",
        "# Shuffling the training data\n",
        "\n",
        "gen_nums = tf.cast(tf.linspace(0.0,X_train_frame.shape[0]-1,X_train_frame.shape[0]-1), dtype=tf.int32)\n",
        "indexes = tf.random.shuffle(gen_nums)\n",
        "\n",
        "\n",
        "X_train = X_train_frame.get_values()[indexes,:]    # numpy array\n",
        "y_train = y_train_frame.get_values()[indexes]\n",
        "A_train = A_train_frame.get_values()[indexes]\n",
        "\n",
        "\n",
        "# Shuffling the testing data\n",
        "\n",
        "gen_nums = tf.cast(tf.linspace(0.0,X_test.shape[0]-1,X_test.shape[0]-1), dtype=tf.int32)\n",
        "indexes = tf.random.shuffle(gen_nums)\n",
        "\n",
        "\n",
        "X_test = X_test_frame.get_values()[indexes,:]   # numpy array\n",
        "y_test = y_test_frame.get_values()[indexes]\n",
        "A_test = A_test_frame.get_values()[indexes]\n",
        "\n",
        "###############################################################################\n",
        "m,n = X_train.shape\n",
        "\n",
        "m2, n2 = X_test.shape\n",
        "\n",
        "\n",
        "\n",
        "# Convert to Tensors\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "\n",
        "y_train = tf.convert_to_tensor(y_train, dtype= tf.float32)\n",
        "y_train = tf.reshape(y_train,(m,1))\n",
        "y_test = tf.convert_to_tensor(y_test, dtype = tf.float32)\n",
        "y_test = tf.reshape(y_test,(m2,1))\n",
        "\n",
        "\n",
        "\n",
        "A_train = tf.convert_to_tensor(A_train, dtype = tf.float32)\n",
        "A_train = tf.reshape(A_train,(m,1))\n",
        "\n",
        "A_test = tf.convert_to_tensor(A_test, dtype = tf.float32)\n",
        "A_test = tf.reshape(A_test,(m2,1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t9c0T72_jgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "53974c45-5b5d-44e7-f0dd-12e6a0645f2d"
      },
      "source": [
        "loss = Custom_Loss()\n",
        "\n",
        "\n",
        "loss.mmd_loss(X_train[:100000,:],X_test[:100000,:],0.1)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Summary name MMD Loss is illegal; using MMD_Loss instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=2995575, shape=(), dtype=float32, numpy=1e-05>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyjvqzw2GklZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Binary(logits):\n",
        "  \n",
        "  y_soft = tf.sigmoid(logits)\n",
        "  y = tf.cast((y_soft>=0.5),dtype= tf.float32)\n",
        "  \n",
        "  return y\n",
        "\n",
        "def accuracy(y,y_):\n",
        "    y_ = tf.nn.sigmoid(y_)\n",
        "    ans = tf.cast((y_>=0.5),dtype= tf.float32)\n",
        "    res = tf.cast(tf.equal(ans,y),tf.float32)\n",
        "    \n",
        "    return tf.reduce_mean(res)\n",
        "  \n",
        "\n",
        "def RW_accuracy(y1,y1_, y2, y2_):\n",
        "    rw = tf.multiply(tf.constant(0.5),(accuracy(y1,y1_) + accuracy(y2,y2_) ))\n",
        "    return rw\n",
        "\n",
        "\n",
        "def delta_dp(model, dataset,key,label):\n",
        "  \n",
        "  DP_male_data_frame,DP_male_label_frame,A_male_frame, DP_female_data_frame, DP_female_label_frame,A_female_frame = filter_dataframe_dp(dataset,key,label)\n",
        "  \n",
        "  \n",
        "  \n",
        "  DP_male_data = tf.convert_to_tensor(DP_male_data_frame.to_numpy() ,dtype=tf.float32) \n",
        "  DP_female_data = tf.convert_to_tensor(DP_female_data_frame.to_numpy() ,dtype=tf.float32) \n",
        "  \n",
        "  DP_male_label = tf.convert_to_tensor(DP_male_label_frame.to_numpy() ,dtype=tf.float32) \n",
        "  DP_female_label = tf.convert_to_tensor(DP_female_label_frame.to_numpy() ,dtype=tf.float32) \n",
        "  \n",
        "  A_DP_male = tf.convert_to_tensor(A_male_frame.to_numpy(), dtype= tf.float32)\n",
        "  A_DP_female = tf.convert_to_tensor(A_female_frame.to_numpy(), dtype= tf.float32)\n",
        "\n",
        "  DP_male_y_ = model(DP_male_data)\n",
        "  DP_female_y_ = model(DP_female_data)\n",
        "\n",
        "  \n",
        "  \n",
        "  DP_female = tf.reduce_mean(tf.multiply(DP_female_y_ , tf.subtract(tf.constant(1.0),A_DP_female)))\n",
        "  DP_male = tf.reduce_mean(tf.multiply(DP_male_y_ , A_DP_male))\n",
        "  \n",
        "  delta_DP = tf.abs(DP_female - DP_male )\n",
        " \n",
        "\n",
        "  print(\"Female Accuracy: {}\".format(accuracy(DP_female_label,DP_female_y_) ))\n",
        "  print(\"Male Accuracy: {}\".format(accuracy(DP_male_label,DP_male_y_) ))\n",
        "  \n",
        "  return delta_DP.numpy()\n",
        "\n",
        "\n",
        "\n",
        "def RW_accuracy_v2(model, dataset,key,label):\n",
        "  \n",
        "    male_data_frame,male_label_frame, female_data_frame, female_label_frame = filter_dataframe(dataset,key,label)\n",
        "   \n",
        "    male_data = tf.convert_to_tensor(male_data_frame.to_numpy() ,dtype=tf.float32) \n",
        "    female_data = tf.convert_to_tensor(female_data_frame.to_numpy() ,dtype=tf.float32) \n",
        "    \n",
        "    male_label = tf.convert_to_tensor(male_label_frame.to_numpy() ,dtype=tf.float32) \n",
        "    female_label = tf.convert_to_tensor(female_label_frame.to_numpy() ,dtype=tf.float32) \n",
        "    \n",
        "    male_y_ = model(male_data)\n",
        "    female_y_ = model(female_data)\n",
        "   \n",
        "\n",
        "    rw = RW_accuracy(female_label,female_y_,male_label,male_y_)    \n",
        "    \n",
        "    return rw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2x4I874HXjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(tf.keras.Model) :\n",
        "  \n",
        "  def __init__(self,input_dim):\n",
        "    \n",
        "    super(MLP,self).__init__()\n",
        "    \n",
        "    self.h1 = tf.keras.Sequential([tf.keras.layers.Dense(input_shape=(input_dim,),units=200,activation=tf.nn.relu),])\n",
        "    \n",
        "    self.h2 = tf.keras.Sequential([tf.keras.layers.Dense(units=300,activation=tf.nn.relu),])\n",
        "    \n",
        "    self.h3 = tf.keras.Sequential([tf.keras.layers.Dense(units = 500,activation=tf.nn.relu),])\n",
        "    \n",
        "    self.out = tf.keras.Sequential([ tf.keras.layers.Dense(units=1),])\n",
        "    \n",
        "  \n",
        "    self.optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "    self.global_step = tf.Variable(0)\n",
        "    \n",
        "  \n",
        "\n",
        "  def call(self, x):\n",
        "    \n",
        "    x = self.h1(x)\n",
        "    x = self.h2(x)\n",
        "    x = self.h3(x)\n",
        "    output = self.out(x)\n",
        "    \n",
        "    return output\n",
        "    \n",
        "    \n",
        "  def loss(self, y,y_):\n",
        "    print(y.shape, y_.shape)\n",
        "    mloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=y_))\n",
        "    return mloss\n",
        "  \n",
        "  \n",
        "  def gradient(self, x,y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_ = self.call(x)\n",
        "        mloss = self.loss(y,y_)\n",
        "        return mloss, tape.gradient(mloss,self.out.trainable_variables)\n",
        "      \n",
        "      \n",
        "    \n",
        "  def train(self, X, y, epochs, accuracy):\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        print(\"Epoch: \", ep)\n",
        "        y_ = self.call(X)\n",
        "        mloss, grad = self.gradient(X,y)\n",
        "        self.optimizer.apply_gradients(zip(grad, self.out.trainable_variables),global_step=self.global_step)\n",
        "\n",
        "        print(\"Loss: \",mloss.numpy(), \"######### \",\" Accuracy: \", accuracy(y,y_).numpy())\n",
        "\n",
        "    return self.out    \n",
        " \n",
        "\n",
        "  def predict(self):\n",
        "    return self.call"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nO05OwcDPer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP_MMD(tf.keras.Model) :\n",
        "  \n",
        "  def __init__(self,input_dim):\n",
        "    \n",
        "    super(MLP_MMD,self).__init__()\n",
        "    \n",
        "    self.h1 = tf.keras.Sequential([tf.keras.layers.Dense(input_shape=(input_dim,),units=200,activation=tf.nn.relu),])\n",
        "    \n",
        "    self.h2 = tf.keras.Sequential([tf.keras.layers.Dense(input_shape = (200,), units=300,activation=tf.nn.relu),])\n",
        "    \n",
        "    self.h3 = tf.keras.Sequential([tf.keras.layers.Dense(input_shape= (300,), units = 500,activation=tf.nn.relu),])\n",
        "    \n",
        "    self.out = tf.keras.Sequential([ tf.keras.layers.Dense(input_shape=(500,),units=1),])\n",
        "    \n",
        "  \n",
        "    self.optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "    self.global_step = tf.Variable(0)\n",
        "    \n",
        "    self.custom_loss = Custom_Loss()\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  def call(self, x):\n",
        "    \n",
        "    x = self.h1(x)\n",
        "    x = self.h2(x)\n",
        "    x = self.h3(x)\n",
        "    output = self.out(x)\n",
        "    \n",
        "    return output\n",
        "    \n",
        "    \n",
        "  def loss(self, y,y_ , z,z_, alpha):\n",
        "    mloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=y_))\n",
        "    mmd_loss = self.custom_loss.mmd_loss(z,z_,alpha)\n",
        "    loss = mloss + mmd_loss\n",
        "    \n",
        "    return loss\n",
        "  \n",
        "  \n",
        "  def gradient(self, x,y, z,z_, alpha):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_ = self.call(x)\n",
        "        loss = self.loss(y,y_, z,z_, alpha)\n",
        "        return loss, tape.gradient(loss,self.out.trainable_variables)\n",
        "      \n",
        "      \n",
        "    \n",
        "  def train(self,dataset,epochs,accuracy,alpha, train_using_label='y'):\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        print(\"Epoch: \", ep)\n",
        "        \n",
        "        sex_male_data,sex_male_label , sex_female_data,sex_female_label = filter_dataframe(dataset,'A',train_using_label)\n",
        "        \n",
        "        sex_male_data,sex_male_label , sex_female_data,sex_female_label = convert_to_tensors([sex_male_data.to_numpy(),sex_male_label.to_numpy(),sex_female_data.to_numpy(),sex_female_label.to_numpy()])\n",
        "        \n",
        "        X = tf.concat([sex_male_data,sex_female_data],axis=0)\n",
        "        y = tf.concat([sex_male_label,sex_female_label],axis=0)\n",
        "        \n",
        "        y = tf.reshape(y,(y.shape[0],1))\n",
        "        \n",
        "        \n",
        "        \n",
        "        h1 = self.h1(sex_male_data)\n",
        "        h2= self.h2(h1)\n",
        "        z_male  = self.h3(h2)\n",
        "        \n",
        "        h1 = self.h1(sex_female_data)\n",
        "        h2= self.h2(h1)\n",
        "        z_female  = self.h3(h2)\n",
        "    \n",
        "\n",
        "        y_male = self.out(z_male)\n",
        "        y_female = self.out(z_female)\n",
        "        \n",
        "        \n",
        "        \n",
        "        loss, grad = self.gradient(X,y,z_male,z_female, alpha)\n",
        "        \n",
        "        self.optimizer.apply_gradients(zip(grad, self.out.trainable_variables),global_step=self.global_step)\n",
        "        \n",
        "        if ep%10==0:\n",
        "          print(\"Loss: \",loss.numpy(), \"######### \",\" Male Accuracy : \", accuracy(sex_male_label,y_male).numpy(), \" Female Accuracy : \", accuracy(sex_female_label,y_female).numpy())\n",
        "\n",
        "    return self.out    \n",
        " \n",
        "\n",
        "  def predict(self):\n",
        "    return self.call"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHpnT8APJOIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "27c84fde-9929-4829-d014-99cf9ed1d44d"
      },
      "source": [
        "classifier = MLP(n)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsWNVk83JcfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "classifier.train(X_train,y_train, epochs, accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLUIOZiEJiUr",
        "colab_type": "code",
        "outputId": "535b4ef7-4556-478c-fca3-bd23dfd57953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(\"Total test Accuracy: \", accuracy(y_test,classifier.predict()(X_test)).numpy() )\n",
        "\n",
        "print(\"Delta DP: \", delta_dp(classifier.predict(), dataset_test_frame,'sex_Female','y' )) \n",
        "\n",
        "print('Reweighted Accuracy: {}'.format(RW_accuracy_v2(classifier.predict(), dataset_test_frame,'A','y')))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total test Accuracy:  0.7637592\n",
            "Female Accuracy: 0.8175638318061829\n",
            "Male Accuracy: 0.6390597820281982\n",
            "Delta DP:  37.122173\n",
            "Reweighted Accuracy: 0.7283117771148682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6fyn2nSkgro",
        "colab_type": "text"
      },
      "source": [
        "### For A:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc4-5anxWMkQ",
        "colab_type": "code",
        "outputId": "871d8118-653b-47dd-9219-a29f475715d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train_uncr2 = X_train_frame.drop(['sex_Male', 'sex_Female'], axis = 1).to_numpy()\n",
        "X_test_uncr2 = X_test_frame.drop([],axis = 1).to_numpy()\n",
        "\n",
        "X_test_uncr2 = X_test_frame.drop(['sex_Male', 'sex_Female'], axis = 1).to_numpy()\n",
        "\n",
        "dataset_test_frame_uncr2 = dataset_test_frame.drop(['sex_Male', 'sex_Female'], axis = 1) \n",
        "\n",
        "X_train_uncr2 = tf.convert_to_tensor(X_train_uncr2, dtype=tf.float32)\n",
        "X_test_uncr2 = tf.convert_to_tensor(X_test_uncr2, dtype= tf.float32)\n",
        "\n",
        "\n",
        "n3= X_train_uncr2.shape[1]\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xflhgvkmky82",
        "colab_type": "code",
        "outputId": "d85d241f-f83c-499a-e275-20c072415ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classifier3 = MLP(n3)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32560, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-uktlmekyqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "classifier3.train(X_train_uncr2[1:],A_train,epochs,accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CctYiHszk5I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Test Accuracy: \", accuracy(A_test,classifier3.predict()(X_test_uncr2[1:])).numpy() )\n",
        "\n",
        "print(\"Delta DP: \", delta_dp(classifier3.predict(), dataset_test_frame_uncr2,'A','A' )) \n",
        "\n",
        "print('Reweighted Accuracy: {}'.format(RW_accuracy_v2(classifier3.predict(), dataset_test_frame_uncr2,'A','A')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA-Q80BRLTJS",
        "colab_type": "text"
      },
      "source": [
        "## Q2. Now, let’s try a neural network solution. Train a neural network with at least one hidden layer as your binary classifier. Use a cross-entropy loss, and include an MMD regularizer on the final hidden layer of the network. You can find Pytorch code for MMD in mmd.py in the assignment folder. The regularizer should measure the MMD between the internal repre- sentation of the network for each group (A = 0 or 1), multiplied by a coefficient hyperparameter α. Start with α = 0.1. Note, this is not really pre-processing, since we’re learning the solution end-to-end. As in the previous question, learn to predict Y and A with this model, and report the same results. Which method was better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1WFMRBbtMPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_mmd = MLP_MMD(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq0SA-82Kr1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "classifier_mmd.train(dataset_train_frame, epochs, accuracy, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS1sF5Lc-7d9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Total test Accuracy: \", accuracy(y_test,classifier_mmd.predict()(X_test)).numpy() )\n",
        "\n",
        "print(\"Delta DP: \", delta_dp(classifier_mmd.predict(), dataset_test_frame,'sex_Female','y' )) \n",
        "\n",
        "print('Reweighted Accuracy: {}'.format(RW_accuracy_v2(classifier_mmd.predict(), dataset_test_frame,'A','y')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRLPIT2gCAGs",
        "colab_type": "text"
      },
      "source": [
        "###  Training Using A:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCwKDT7UCFV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "b49c6214-735b-4f58-df0d-06f217eec195"
      },
      "source": [
        "classifier_mmd2 = MLP_MMD(n)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2RUaE-6CTBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "classifier_mmd2.train(dataset_train_frame, epochs, accuracy, 0.1, train_using_label='A') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjatQ_w7ERRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "0f79ed7e-c744-4d69-b778-2682c9cab450"
      },
      "source": [
        "print(\"Total test Accuracy: \", accuracy(y_test,classifier_mmd2.predict()(X_test)).numpy() )\n",
        "\n",
        "print(\"Delta DP: \", delta_dp(classifier_mmd2.predict(), dataset_test_frame,'sex_Female','y' )) \n",
        "\n",
        "print('Reweighted Accuracy: {}'.format(RW_accuracy_v2(classifier_mmd2.predict(), dataset_test_frame,'A','y')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total test Accuracy:  0.7637592\n",
            "Female Accuracy: 0.8908753395080566\n",
            "Male Accuracy: 0.6999998092651367\n",
            "Delta DP:  3.1202517\n",
            "Reweighted Accuracy: 0.7954375743865967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3QvJfgNAQye",
        "colab_type": "text"
      },
      "source": [
        "## Q 2.3 Hyperparameters can take a number of useful values. Try to find the useful range of the hyperparameter α. Report this range. Plot the values of accuracy and ∆ DP against various α in this range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRmgMMUnDOWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha_list = [0.01,1,10,100]\n",
        "epochs = 1000\n",
        "MMD_classifiers = [MLP_MMD(n),MLP_MMD(n),MLP_MMD(n),MLP_MMD(n)]\n",
        "\n",
        "for i, alpha in enumerate(alpha_list):\n",
        "  MMD_classifiers[i].train(dataset_train_frame, epochs, accuracy, alpha, train_using_label='y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPJkEpN0FnhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for mclassifier in MMD_classifiers:\n",
        "  \n",
        "\n",
        "  print(\"Test Accuracy: \", accuracy(A_test,mclassifier.predict()(X_test)).numpy() )\n",
        "\n",
        "  print(\"Delta DP: \", delta_dp(mclassifier.predict(), dataset_test_frame,'A','y' )) \n",
        "\n",
        "  print('Reweighted Accuracy: {}'.format(RW_accuracy_v2(mclassifier.predict(), dataset_test_frame,'A','y')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9KsCuqiAYbW",
        "colab_type": "text"
      },
      "source": [
        "## Q 2.4  We compared two methods of removing sensitive information. What do you think is the best way to compare various methods for this task?\n",
        "\n",
        "\n",
        "I think the best method is the second one using the MMD loss, because it is trying to  equalize the performance between the two sensitive attributes ( Male and Female), but there is something that observed during the training, as the accuracy for the male and female keeps fluctuating, as at the beginning the network get 100% accuracy for Male and then after some epochs it reflects its behavior to get full score for female, I think an explanation for this that it is a way for the network trying to find a point from which can find the equilibrium between the latent representation of the two genders ( sensitive attributes). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anmZvQQTAcKc",
        "colab_type": "text"
      },
      "source": [
        "## Q 2.5 Can you think of any other ways you might remove information about A from a representation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyJHLirmL-yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Using VFAE network architecture."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}